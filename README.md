# Autocannon - HTTP Benchmarking Tool

A fast, lightweight HTTP benchmarking tool written in Go that helps you measure the performance of your web services and APIs.

## Features

- ğŸš€ **High Performance**: Concurrent HTTP requests using goroutines
- ğŸ“Š **Detailed Statistics**: Comprehensive metrics including latency, throughput, and error rates
- ğŸ¯ **Flexible Configuration**: Customizable connections, duration, timeouts, and HTTP methods
- ğŸ“ˆ **Beautiful Output**: Color-coded console output with formatted tables
- ğŸ’¾ **JSON Export**: Save results to JSON files for further analysis
- ğŸ” **Status Code Tracking**: Detailed breakdown of HTTP response codes
- â±ï¸ **Latency Metrics**: Min, max, and average response times
- ğŸ› ï¸ **Debug Mode**: Verbose logging for troubleshooting

## Installation

### From Source

```bash
git clone <repository-url>
cd autocannon
go build -o autocannon main.go
```

### Using Go Install

```bash
go install github.com/your-username/autocannon@latest
```

## Usage

### Basic Usage

```bash
# Simple GET request benchmark
./autocannon -uri http://localhost:3000

# Benchmark with custom parameters
./autocannon -uri http://localhost:3000 -clients 50 -duration 30
```

### Command Line Options

| Flag | Default | Description |
|------|---------|-------------|
| `-uri` | *required* | The URI to benchmark against |
| `-clients` | 10 | Number of concurrent connections |
| `-duration` | 10 | Duration of the test in seconds |
| `-timeout` | 10 | Request timeout in seconds |
| `-method` | GET | HTTP method to use |
| `-body` | "" | Request body to send |
| `-expect` | 200 | Expected HTTP status code |
| `-output` | "" | Output file for JSON results |
| `-debug` | false | Enable debug logging |

### Examples

#### Basic GET Request
```bash
./autocannon -uri https://httpbin.org/get
```

#### High Load Test
```bash
./autocannon -uri http://localhost:8080/api/health -clients 100 -duration 60
```

#### POST Request with Body
```bash
./autocannon -uri http://localhost:8080/api/users -method POST -body '{"name":"test"}'
```

#### Save Results to File
```bash
./autocannon -uri http://localhost:3000 -output results.json
```

#### Debug Mode
```bash
./autocannon -uri http://localhost:3000 -debug
```

## Output

The tool provides two main types of output:

### Console Output

```
Starting autocannon with the following parameters:
URI: http://localhost:3000
Connections: 10
Duration: 10 seconds
Timeout: 10 seconds
Method: GET
Expected status: 200
Debug: false
Starting autocannon...

Benchmark Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       METRIC        â”‚   VALUE    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total Requests      â”‚      15420 â”‚
â”‚ Successful Requests â”‚      15420 â”‚
â”‚ Failed Requests     â”‚          0 â”‚
â”‚ Timeouts           â”‚          0 â”‚
â”‚ Requests/sec       â”‚    1542.00 â”‚
â”‚ Average Latency    â”‚       6.48 â”‚
â”‚ Min Latency        â”‚       1.23 â”‚
â”‚ Max Latency        â”‚      45.67 â”‚
â”‚ Total Data Received â”‚    1234567 â”‚
â”‚ Error Rate         â”‚       0.00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Status Code Distribution:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STATUS CODE â”‚ COUNT â”‚ PERCENTAGE â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     200     â”‚ 15420 â”‚   100.00%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### JSON Output

When using the `-output` flag, results are saved in JSON format:

```json
{
  "connections": 10,
  "durationSeconds": 10,
  "totalRequests": 15420,
  "successfulRequests": 15420,
  "failedRequests": 0,
  "timeouts": 0,
  "requestsPerSecond": 1542.00,
  "averageLatencyMs": 6.48,
  "minLatencyMs": 1.23,
  "maxLatencyMs": 45.67,
  "bytesRead": 1234567,
  "bytesWritten": 308400,
  "errorRate": 0.00,
  "statusCodes": {
    "200": 15420
  },
  "timestamp": "2025-09-21T10:30:00Z"
}
```

## Metrics Explained

- **Total Requests**: Total number of HTTP requests sent
- **Successful Requests**: Number of requests that completed without errors
- **Failed Requests**: Number of requests that failed (network errors, etc.)
- **Timeouts**: Number of requests that exceeded the timeout duration
- **Requests/sec**: Average throughput (requests per second)
- **Average Latency**: Mean response time in milliseconds
- **Min/Max Latency**: Fastest and slowest response times
- **Total Data Received**: Total bytes received from the server
- **Error Rate**: Percentage of failed requests
- **Status Code Distribution**: Breakdown of HTTP response codes

## Use Cases

- **API Performance Testing**: Measure the performance of REST APIs
- **Load Testing**: Determine how many concurrent users your service can handle
- **Regression Testing**: Compare performance before and after code changes
- **Infrastructure Testing**: Test the limits of your server infrastructure
- **CI/CD Integration**: Automated performance testing in deployment pipelines

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Dependencies

- [tablewriter](https://github.com/olekukonko/tablewriter) - For formatted console output
- [chalk](https://github.com/ttacon/chalk) - For colored terminal output

## Acknowledgments

- Inspired by the Node.js [autocannon](https://github.com/mcollina/autocannon) tool
- Built with the power and simplicity of Go's standard library